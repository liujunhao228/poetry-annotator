import streamlit as st
import plotly.express as px
import pandas as pd
from datetime import datetime, timedelta

from data_visualizer.config import APP_TITLE, DB_PATHS
from data_visualizer.utils import logger
from data_visualizer.app.cache_manager import get_db_manager, get_data_processor
from data_visualizer.app.data_fetcher import (
    get_model_performance_data,
    get_poem_count_by_author_data,
    get_emotion_distribution_data,
    get_frequent_emotion_combinations_data,
    get_frequent_poem_emotion_sets_data,
    get_apriori_results_data,
    get_model_annotation_trends_data,
    get_poem_length_distribution_data
)
from data_visualizer.app.ui_components import (
    display_model_performance,
    display_author_poem_count,
    display_emotion_sunburst,
    display_frequent_combinations
)
from data_visualizer.app.comparison_charts import (
    display_poem_length_comparison_chart,
    display_annotation_trend_comparison_chart
)

def run_app():
    """Main function to run the Streamlit application."""
    st.set_page_config(layout="wide", page_title=APP_TITLE)
    st.title(APP_TITLE)

    # --- Sidebar Controls ---
    with st.sidebar:
        st.title("æ§åˆ¶é¢æ¿")

        if st.button("æ¸…é™¤æ‰€æœ‰ç¼“å­˜å¹¶åˆ·æ–°", help="å¼ºåˆ¶æ¸…é™¤æ‰€æœ‰åº”ç”¨çš„ç¼“å­˜ï¼Œä»æ•°æ®åº“é‡æ–°åŠ è½½æ‰€æœ‰æ•°æ®ã€‚"):
            st.cache_data.clear()
            st.cache_resource.clear()
            st.session_state.clear() # æ¸…é™¤ä¼šè¯çŠ¶æ€
            logger.info("æ‰€æœ‰ç¼“å­˜å·²æ¸…é™¤ï¼Œåº”ç”¨å³å°†åˆ·æ–°ã€‚")
            st.rerun()

        st.markdown("---")
        
        view_mode = st.radio("è§†å›¾æ¨¡å¼:", ("å•åº“åˆ†æ", "åŒåº“å¯¹æ¯”"), key="view_mode_selector", horizontal=True)

        db_keys_options = list(DB_PATHS.keys())
        selected_db_key = None
        if view_mode == "å•åº“åˆ†æ":
            selected_db_key = st.selectbox("é€‰æ‹©æ•°æ®åº“:", db_keys_options)
        
        st.markdown("---")
        st.header("æ•°æ®è¿‡æ»¤")
        today = datetime.now()
        default_start_date = today - timedelta(days=90)
        date_range = st.date_input("é€‰æ‹©æ ‡æ³¨æ—¥æœŸèŒƒå›´", value=(default_start_date, today), key="annotation_date_filter")
        if len(date_range) == 2:
            start_date_iso = date_range[0].isoformat() + "T00:00:00Z"
            end_date_iso = date_range[1].isoformat() + "T23:59:59Z"
        else:
            start_date_iso, end_date_iso = None, None

    # --- Main Panel with Tabs ---
    tab1, tab2, tab3, tab4 = st.tabs(["æ ‡æ³¨åˆ†æ", "è¯—è¯æ•°æ®æ¦‚è§ˆ", "æƒ…æ„Ÿåˆ†æ", "å…³äºä¸æ€§èƒ½"])

    if view_mode == "å•åº“åˆ†æ":
        if selected_db_key:
            with tab1:
                st.header(f"æ ‡æ³¨ç»“æœåˆ†æ: {selected_db_key}")
                st.subheader("æ¨¡å‹æ€§èƒ½æ€»è§ˆ")
                display_model_performance(selected_db_key)
                
                header_col, button_col = st.columns([0.85, 0.15])
                with header_col:
                    st.subheader("æ ‡æ³¨è¶‹åŠ¿")
                with button_col:
                    if st.button("ğŸ”„ åˆ·æ–°è¶‹åŠ¿", key=f"refresh_trends_{selected_db_key}", help="ä»…é‡æ–°åŠ è½½è¶‹åŠ¿æ•°æ®"):
                        get_model_annotation_trends_data.clear()

                trends_df = get_model_annotation_trends_data(selected_db_key, start_date_iso, end_date_iso)
                if not trends_df.empty:
                    fig_trend = px.line(trends_df.groupby('annotation_date')['completed'].sum().reset_index(), 
                                        x='annotation_date', y='completed', title="æ¯æ—¥æˆåŠŸæ ‡æ³¨æ•°é‡",
                                        labels={'completed': 'æˆåŠŸæ ‡æ³¨æ•°', 'annotation_date': 'æ—¥æœŸ'})
                    st.plotly_chart(fig_trend, use_container_width=True)
                else:
                    st.info("æ‰€é€‰æ—¥æœŸèŒƒå›´å†…æ— æ ‡æ³¨è¶‹åŠ¿æ•°æ®ã€‚")

            with tab2:
                st.header(f"è¯—è¯æ•°æ®æ¦‚è§ˆ: {selected_db_key}")
                
                header_col, button_col = st.columns([0.85, 0.15])
                with header_col:
                    st.subheader("è¯—äººä½œå“æ•°é‡åˆ†å¸ƒ")
                with button_col:
                    if st.button("ğŸ”„ åˆ·æ–°å›¾è¡¨", key=f"refresh_poets_{selected_db_key}", help="ä»…é‡æ–°åŠ è½½è¯—äººæ•°æ®"):
                        get_poem_count_by_author_data.clear()
                
                top_n_authors = st.slider("æ˜¾ç¤º Top N åˆ›ä½œè€…", 5, 50, 20, key=f"author_count_{selected_db_key}")
                display_author_poem_count(selected_db_key, top_n=top_n_authors)
                
                st.subheader("è¯—è¯é•¿åº¦åˆ†å¸ƒ")
                method_display = st.radio("é€‰æ‹©ç»Ÿè®¡æ–¹æ³•", ('æŒ‰å­—æ•°', 'æŒ‰è¯æ•°'), key=f'len_method_{selected_db_key}', horizontal=True)
                method = {'æŒ‰å­—æ•°': 'characters', 'æŒ‰è¯æ•°': 'words'}[method_display]
                df = get_poem_length_distribution_data(selected_db_key, method)
                if not df.empty:
                    fig = px.bar(df, x='length_band', y='count', title=f'è¯—è¯é•¿åº¦åˆ†å¸ƒ ({method_display})')
                    st.plotly_chart(fig, use_container_width=True)

            with tab3:
                st.header(f"æƒ…æ„Ÿç±»å‹åˆ†æ: {selected_db_key}")
                emotion_dist_df = get_emotion_distribution_data(selected_db_key)

                if emotion_dist_df.empty:
                    st.warning("æœªæ‰¾åˆ°æƒ…æ„Ÿåˆ†å¸ƒæ•°æ®ã€‚è¯·ç¡®ä¿å·²è¿è¡Œæ•°æ®è¿ç§»è„šæœ¬ï¼Œæˆ–è¯¥åº“ä¸­æœ‰å·²å®Œæˆçš„æ ‡æ³¨ã€‚")
                else:
                    header_col, button_col = st.columns([0.85, 0.15])
                    with header_col:
                        st.subheader("æƒ…æ„Ÿç±»å‹å±‚çº§åˆ†å¸ƒ")
                    with button_col:
                        if st.button("ğŸ”„ åˆ·æ–°åˆ†å¸ƒ", key=f"refresh_emotion_dist_{selected_db_key}", help="ä»…é‡æ–°åŠ è½½æƒ…æ„Ÿåˆ†å¸ƒæ•°æ®"):
                            get_emotion_distribution_data.clear()
                    display_emotion_sunburst(selected_db_key)

                    st.subheader("æƒ…æ„Ÿé¢‘æ¬¡ç»Ÿè®¡")
                    # ... (rest of emotion frequency code) ...
                    emotion_freq_df = emotion_dist_df.sort_values('count', ascending=False)
                    top_n = st.slider("æ˜¾ç¤º Top N æƒ…æ„Ÿç±»åˆ«", 10, min(100, len(emotion_freq_df)), 20, key=f"emotion_freq_slider_{selected_db_key}")
                    df_to_plot = emotion_freq_df.head(top_n)
                    fig_height = max(400, len(df_to_plot) * 30 + 100)
                    fig_bar_all = px.bar(df_to_plot, x='count', y='name_zh', orientation='h', title=f'æƒ…æ„Ÿç±»åˆ«é¢‘æ¬¡æ’è¡Œ (Top {top_n})', labels={'name_zh': 'æƒ…æ„Ÿç±»åˆ«', 'count': 'å‡ºç°æ¬¡æ•°'}, text='percentage', height=fig_height).update_yaxes(categoryorder="total ascending")
                    st.plotly_chart(fig_bar_all, use_container_width=True)


                    st.subheader("æƒ…æ„Ÿå…±ç°ä¸å…³è”è§„åˆ™æŒ–æ˜")
                    tab_sql_sentence, tab_sql_poem, tab_apriori = st.tabs(["**å•å¥å†…å…±ç° (SQL è®¡æ•°)**", "**å…¨è¯—å†…å…±ç° (SQL è®¡æ•°)**", "**é«˜çº§æŒ–æ˜ (Apriori)**"])

                    with tab_sql_sentence:
                        st.markdown("âš¡ï¸ **å¿«é€Ÿæ¦‚è§ˆ**: ä½¿ç”¨ SQL ç›´æ¥ç»Ÿè®¡**ä¸€å¥è¯—ä¸­**å…±åŒå‡ºç°çš„å¤šç§æƒ…æ„Ÿã€‚")
                        top_n_sentence = st.slider("é€‰æ‹©æ˜¾ç¤ºç»„åˆæ•°é‡", 5, 50, 15, key=f"combo_sentence_{selected_db_key}")
                        display_frequent_combinations(selected_db_key, top_n_sentence)

                    with tab_sql_poem:
                        st.markdown("âš¡ï¸ **å¿«é€Ÿæ¦‚è§ˆ**: ä½¿ç”¨ SQL ç›´æ¥ç»Ÿè®¡**ä¸€é¦–è¯—å†…**ï¼ˆä¸ä¸€å®šåœ¨åŒä¸€å¥ï¼‰å…±åŒå‡ºç°çš„ä¸åŒæƒ…æ„Ÿã€‚")
                        top_n_poem = st.slider("é€‰æ‹©æ˜¾ç¤ºç»„åˆæ•°é‡", 5, 50, 15, key=f"combo_poem_{selected_db_key}")
                        sets_df = get_frequent_poem_emotion_sets_data(selected_db_key, top_n_poem)
                        if not sets_df.empty:
                            st.dataframe(sets_df, column_config={"set_readable": st.column_config.TextColumn("æƒ…æ„Ÿé›†åˆ", width="large"), "set_count": st.column_config.NumberColumn("å‡ºç°æ¬¡æ•°", format="%d é¦–"), "poem_example": st.column_config.TextColumn("ç¤ºä¾‹è¯—è¯")}, use_container_width=True, hide_index=True)
                        else:
                            st.info("æš‚æ— å…¨è¯—å†…é«˜é¢‘æƒ…æ„Ÿé›†åˆæ•°æ®ã€‚")

                    with tab_apriori:
                        st.markdown("ğŸ”¬ **æ·±åº¦æŒ–æ˜**: ä½¿ç”¨ Apriori ç®—æ³•å‘ç°é¢‘ç¹é¡¹é›†ï¼Œæ¢ç´¢ä¸åŒç¨€æœ‰åº¦çš„æƒ…æ„Ÿç»„åˆã€‚")
                        st.info("æ­¤åŠŸèƒ½è®¡ç®—å¯†é›†ã€‚ä¸ºæå‡ä½“éªŒï¼ŒæŒ–æ˜å°†åœ¨æ‚¨ç‚¹å‡»æŒ‰é’®åå¯åŠ¨ã€‚")
                        
                        session_key = f"apriori_started_{selected_db_key}"
                        if session_key not in st.session_state:
                            st.session_state[session_key] = False
                        
                        if st.button("ğŸš€ å¼€å§‹ Apriori æŒ–æ˜", key=f"start_apriori_{selected_db_key}"):
                            st.session_state[session_key] = True
                        if st.session_state.get(session_key):
                            if st.button("éšè—ç»“æœ", key=f"reset_apriori_{selected_db_key}"):
                                st.session_state[session_key] = False
                                st.rerun()
                            st.markdown("---")
                            col1, col2 = st.columns(2)
                            with col1:
                                level_map = {"å¥å­çº§åˆ«": "sentence", "è¯—è¯çº§åˆ«": "poem"}
                                selected_level_display = st.radio("åˆ†æç²’åº¦", level_map.keys(), key=f"apriori_level_{selected_db_key}", horizontal=True)
                                level = level_map[selected_level_display]
                            with col2:
                                min_length = st.slider("ç»„åˆä¸­æœ€å°‘æƒ…æ„Ÿæ•°", 2, 5, 2, key=f"apriori_len_{selected_db_key}")
                            
                            min_support_percent = st.slider("æœ€å°æ”¯æŒåº¦ (%)", 0.1, 10.0, 1.0, step=0.1, key=f"apriori_support_{selected_db_key}", help="ä¸€ä¸ªæƒ…æ„Ÿç»„åˆå‡ºç°çš„é¢‘ç‡ã€‚å€¼è¶Šä½ï¼Œå‘ç°çš„ç»„åˆè¶Šç¨€æœ‰ã€è¶Šå¤šã€‚")
                            min_support = min_support_percent / 100.0
                            
                            # æ–°å¢æ€§èƒ½æ§åˆ¶é€‰é¡¹
                            st.markdown("### âš™ï¸ æ€§èƒ½æ§åˆ¶é€‰é¡¹")
                            col3, col4 = st.columns(2)
                            with col3:
                                # æ ¹æ®æœ€å°æ”¯æŒåº¦è‡ªåŠ¨è®¾ç½®åˆç†çš„äº‹åŠ¡ä¸Šé™
                                recommended_max_transactions = max(1000, int(10000 * (1 - min_support)))  # æ”¯æŒåº¦è¶Šä½ï¼Œå¤„ç†çš„æ•°æ®åº”è¯¥è¶Šå°‘
                                max_transactions = st.slider(
                                    "æœ€å¤§äº‹åŠ¡æ•° (æ§åˆ¶è®¡ç®—è§„æ¨¡)",
                                    100,
                                    50000,
                                    min(recommended_max_transactions, 10000),
                                    key=f"apriori_max_transactions_{selected_db_key}",
                                    help="å‡å°‘æ­¤å€¼å¯åŠ å¿«è®¡ç®—é€Ÿåº¦ä½†å¯èƒ½ä¸¢å¤±ç½•è§æ¨¡å¼"
                                )
                            
                            with col4:
                                # åŠ¨æ€æç¤ºç”¨æˆ·å½“å‰è®¾ç½®å¯èƒ½å¯¼è‡´çš„æ€§èƒ½å½±å“
                                estimated_time = "å‡ ç§’åˆ°å‡ åˆ†é’Ÿ"
                                if min_support < 0.5:
                                    estimated_time = "å‡ åˆ†é’Ÿåˆ°æ•°ååˆ†é’Ÿ"
                                if max_transactions > 10000:
                                    estimated_time += " (å¯èƒ½ä¼šæ›´é•¿)"
                                st.info(f"é¢„è®¡è®¡ç®—æ—¶é—´: {estimated_time}")
                            # æ˜¾ç¤ºæ­£åœ¨æ‰§è¡Œçš„çŠ¶æ€
                            with st.spinner("æ­£åœ¨è¿›è¡Œ Apriori æŒ–æ˜ï¼Œè¯·ç¨å€™..."):
                                apriori_results_df = get_apriori_results_data(selected_db_key, level, min_support, min_length, max_transactions)
                            
                            st.markdown("---")
                            st.subheader(f"æŒ–æ˜ç»“æœ (æ”¯æŒåº¦ > {min_support_percent:.1f}%)")
                            if not apriori_results_df.empty:
                                # æ£€æŸ¥æ•°æ®æ¡†é•¿åº¦ï¼Œé¿å…æ»‘å—é”™è¯¯
                                result_count = len(apriori_results_df)
                                if result_count > 1:
                                    top_n_apriori = st.slider("æ˜¾ç¤ºå‰ N æ¡ç»“æœ", 1, result_count, min(25, result_count), key=f"apriori_rows_{selected_db_key}")
                                    display_df = apriori_results_df.head(top_n_apriori)
                                else:
                                    st.info(f"å‘ç° {result_count} ä¸ªç»“æœ")
                                    display_df = apriori_results_df
                                
                                st.dataframe(
                                    display_df, 
                                    column_config={
                                        "itemsets_readable": st.column_config.TextColumn("é«˜é¢‘æƒ…æ„Ÿç»„åˆ", width="large"), 
                                        "support": st.column_config.NumberColumn("æ”¯æŒåº¦", format="%.4f"), 
                                        "length": st.column_config.NumberColumn("ç»„åˆé•¿åº¦")
                                    }, 
                                    use_container_width=True, 
                                    hide_index=True
                                )
                            else:
                                st.warning(f"åœ¨å½“å‰è®¾ç½®ä¸‹æœªå‘ç°ä»»ä½•æƒ…æ„Ÿç»„åˆã€‚è¯·å°è¯•é™ä½æœ€å°æ”¯æŒåº¦æˆ–æœ€å°é•¿åº¦ã€‚")
    else:
        # --- Comparison View Mode (Code remains largely the same, but lazy loading can be applied to Apriori here too) ---
        db_keys_to_compare = db_keys_options[:2] # Default to first two
        
        with tab1:
            # ... (Existing comparison code) ...
            st.header("æ ‡æ³¨ç»“æœåˆ†æ (å¯¹æ¯”)")
            st.subheader("æ¨¡å‹æ€§èƒ½æ€»è§ˆ")
            col1, col2 = st.columns(2)
            with col1:
                st.subheader(db_keys_to_compare[0])
                display_model_performance(db_keys_to_compare[0])
            with col2:
                st.subheader(db_keys_to_compare[1])
                display_model_performance(db_keys_to_compare[1])
            st.subheader("æ ‡æ³¨è¶‹åŠ¿ (å åŠ å¯¹æ¯”)")
            display_annotation_trend_comparison_chart(db_keys_to_compare, start_date_iso, end_date_iso)


        with tab2:
            # ... (Existing comparison code) ...
            st.header("è¯—è¯æ•°æ®æ¦‚è§ˆ (å¯¹æ¯”)")
            st.subheader("åˆ›ä½œè€…ä½œå“æ•°é‡ (å¹¶æ’å¯¹æ¯”)")
            col1, col2 = st.columns(2)
            with col1:
                display_author_poem_count(db_keys_to_compare[0])
            with col2:
                display_author_poem_count(db_keys_to_compare[1])
            st.subheader("è¯—è¯é•¿åº¦åˆ†å¸ƒ (å åŠ å¯¹æ¯”)")
            method_display = st.radio("é€‰æ‹©ç»Ÿè®¡æ–¹æ³•", ('æŒ‰å­—æ•°', 'æŒ‰è¯æ•°'), key='len_method_compare', horizontal=True)
            method = {'æŒ‰å­—æ•°': 'characters', 'æŒ‰è¯æ•°': 'words'}[method_display]
            display_poem_length_comparison_chart(db_keys_to_compare, method, method_display)


        with tab3:
            st.header("æƒ…æ„Ÿåˆ†æ (å¯¹æ¯”)")
            st.subheader("æƒ…æ„Ÿå±‚çº§åˆ†å¸ƒ (å¹¶æ’å¯¹æ¯”)")
            col1, col2 = st.columns(2)
            # ... (Existing comparison sunburst code) ...
            with col1:
                st.subheader(db_keys_to_compare[0])
                display_emotion_sunburst(db_keys_to_compare[0])
            with col2:
                st.subheader(db_keys_to_compare[1])
                display_emotion_sunburst(db_keys_to_compare[1])
            st.markdown("---")
            # ... (Existing comparison diff table code) ...
            st.subheader(f"èšåˆå¯¹æ¯”ï¼šæƒ…æ„Ÿåˆ†ç±»å¼•ç”¨ç™¾åˆ†æ¯”å·®å¼‚ ({db_keys_to_compare[1]} vs {db_keys_to_compare[0]})")
            sunburst_df1 = get_emotion_distribution_data(db_keys_to_compare[0])
            sunburst_df2 = get_emotion_distribution_data(db_keys_to_compare[1])
            if not sunburst_df1.empty and not sunburst_df2.empty:
                df1_comp = sunburst_df1[['name_zh', 'percentage', 'count']].rename(columns={'percentage': f'percentage_{db_keys_to_compare[0]}','count': f'count_{db_keys_to_compare[0]}'})
                df2_comp = sunburst_df2[['name_zh', 'percentage', 'count']].rename(columns={'percentage': f'percentage_{db_keys_to_compare[1]}','count': f'count_{db_keys_to_compare[1]}'})
                merged_comp_df = pd.merge(df1_comp, df2_comp, on='name_zh', how='outer').fillna(0)
                merged_comp_df['percentage_diff'] = merged_comp_df[f'percentage_{db_keys_to_compare[1]}'] - merged_comp_df[f'percentage_{db_keys_to_compare[0]}']
                merged_comp_df = merged_comp_df.sort_values(by='percentage_diff', ascending=False, key=abs)
                st.dataframe(merged_comp_df, column_config={'name_zh': "æƒ…æ„Ÿåˆ†ç±»", f'percentage_{db_keys_to_compare[0]}': st.column_config.NumberColumn(f"{db_keys_to_compare[0]} å æ¯” (%)", format="%.2f"), f'percentage_{db_keys_to_compare[1]}': st.column_config.NumberColumn(f"{db_keys_to_compare[1]} å æ¯” (%)", format="%.2f"), 'percentage_diff': st.column_config.NumberColumn(f"å¢å‡ç™¾åˆ†ç‚¹ ({db_keys_to_compare[1]}-{db_keys_to_compare[0]})", format="%+.2f"), f'count_{db_keys_to_compare[0]}': st.column_config.NumberColumn(f"{db_keys_to_compare[0]} å¼•ç”¨æ•°"), f'count_{db_keys_to_compare[1]}': st.column_config.NumberColumn(f"{db_keys_to_compare[1]} å¼•ç”¨æ•°")}, column_order=['name_zh', f'percentage_{db_keys_to_compare[0]}', f'percentage_{db_keys_to_compare[1]}', 'percentage_diff', f'count_{db_keys_to_compare[0]}', f'count_{db_keys_to_compare[1]}'], use_container_width=True, hide_index=True)
            else:
                st.info("ä¸€ä¸ªæˆ–ä¸¤ä¸ªæ•°æ®åº“ç¼ºå°‘æƒ…æ„Ÿåˆ†å¸ƒæ•°æ®ï¼Œæ— æ³•è¿›è¡Œèšåˆå¯¹æ¯”ã€‚")

            st.markdown("---")
            
            st.subheader(f"èšåˆå¯¹æ¯”ï¼šé«˜é¢‘æƒ…æ„Ÿç»„åˆæ”¯æŒåº¦å·®å¼‚ ({db_keys_to_compare[1]} vs {db_keys_to_compare[0]})")
            st.info("ä½¿ç”¨ Apriori ç®—æ³•åœ¨ **è¯—è¯çº§åˆ«** è¿›è¡Œå¯¹æ¯”æŒ–æ˜ã€‚ä¸ºå‡å°‘è®¡ç®—å¼€é”€ï¼ŒæŒ–æ˜å°†åœ¨ç‚¹å‡»æŒ‰é’®åå¯åŠ¨ã€‚")
            
            session_key_comp = "apriori_started_compare"
            if session_key_comp not in st.session_state:
                st.session_state[session_key_comp] = False

            if st.button("ğŸš€ å¼€å§‹å¯¹æ¯”æŒ–æ˜", key="start_apriori_compare"):
                st.session_state[session_key_comp] = True

            if st.session_state.get(session_key_comp):
                if st.button("éšè—å¯¹æ¯”ç»“æœ", key="reset_apriori_compare"):
                    st.session_state[session_key_comp] = False
                    st.rerun()

                col_a, col_b = st.columns(2)
                with col_a:
                    min_length_compare = st.slider("ç»„åˆä¸­æœ€å°‘æƒ…æ„Ÿæ•°", 2, 5, 2, key="apriori_len_compare")
                with col_b:
                    min_support_percent_compare = st.slider("æœ€å°æ”¯æŒåº¦ (%)", 0.1, 5.0, 0.5, step=0.1, key="apriori_support_compare")
                
                min_support_compare = min_support_percent_compare / 100.0
                level_compare = 'poem'

                apriori_df1 = get_apriori_results_data(db_keys_to_compare[0], level_compare, min_support_compare, min_length_compare)
                apriori_df2 = get_apriori_results_data(db_keys_to_compare[1], level_compare, min_support_compare, min_length_compare)

                if apriori_df1.empty and apriori_df2.empty:
                    st.warning(f"åœ¨å½“å‰è®¾ç½®ä¸‹ï¼Œä¸¤ä¸ªæ•°æ®åº“å‡æœªå‘ç°ä»»ä½•æƒ…æ„Ÿç»„åˆã€‚è¯·å°è¯•é™ä½å‚æ•°ã€‚")
                else:
                    df1_ap_comp = apriori_df1[['itemsets_readable', 'support']].rename(columns={'support': f'support_{db_keys_to_compare[0]}'}),
                    df2_ap_comp = apriori_df2[['itemsets_readable', 'support']].rename(columns={'support': f'support_{db_keys_to_compare[1]}'}),
                    merged_ap_df = pd.merge(df1_ap_comp, df2_ap_comp, on='itemsets_readable', how='outer').fillna(0)
                    merged_ap_df['support_diff'] = merged_ap_df[f'support_{db_keys_to_compare[1]}'] - merged_ap_df[f'support_{db_keys_to_compare[0]}']
                    merged_ap_df = merged_ap_df[(merged_ap_df[f'support_{db_keys_to_compare[0]}'] > 0) | (merged_ap_df[f'support_{db_keys_to_compare[1]}'] > 0)]
                    merged_ap_df = merged_ap_df.sort_values(by='support_diff', ascending=False, key=abs)
                    
                    top_n_apriori_comp = st.slider("æ˜¾ç¤ºå‰ N æ¡å¯¹æ¯”ç»“æœ", 5, len(merged_ap_df), min(25, len(merged_ap_df)), key="apriori_rows_compare")
                    st.dataframe(merged_ap_df.head(top_n_apriori_comp), column_config={'itemsets_readable': "é«˜é¢‘æƒ…æ„Ÿç»„åˆ", f'support_{db_keys_to_compare[0]}': st.column_config.NumberColumn(f"{db_keys_to_compare[0]} æ”¯æŒåº¦", format="%.4f"), f'support_{db_keys_to_compare[1]}': st.column_config.NumberColumn(f"{db_keys_to_compare[1]} æ”¯æŒåº¦", format="%.4f"), 'support_diff': st.column_config.NumberColumn(f"æ”¯æŒåº¦å·®å¼‚ ({db_keys_to_compare[1]}-{db_keys_to_compare[0]})", format="%+.4f")}, column_order=['itemsets_readable', f'support_{db_keys_to_compare[0]}', f'support_{db_keys_to_compare[1]}', 'support_diff'], use_container_width=True, hide_index=True)

    with tab4:
        st.header("å…³äºä¸æ€§èƒ½")
        st.markdown("""
        ### åº”ç”¨ä¼˜åŒ–è¯´æ˜
        æ­¤ç‰ˆæœ¬æ ¹æ®è½»é‡çº§æ€§èƒ½ä¼˜åŒ–æ–¹æ¡ˆè¿›è¡Œäº†å‡çº§ï¼Œä¸»è¦æ”¹è¿›åŒ…æ‹¬ï¼š

        - **ğŸ¯ å±€éƒ¨åˆ·æ–°**: å¤šæ•°å›¾è¡¨å·²é…å¤‡ç‹¬ç«‹çš„åˆ·æ–°æŒ‰é’® (ğŸ”„)ï¼Œåªä¼šæ›´æ–°å¯¹åº”å›¾è¡¨çš„æ•°æ®ï¼Œè€Œéæ•´ä¸ªé¡µé¢ï¼Œå“åº”æ›´å¿«æ·ã€‚
        - **âš¡ï¸ æ‡’åŠ è½½**: è®¡ç®—å¯†é›†çš„ Apriori æŒ–æ˜åŠŸèƒ½ç°å·²é»˜è®¤å…³é—­ï¼Œéœ€ç‚¹å‡»â€œå¼€å§‹æŒ–æ˜â€æŒ‰é’®åæ‰ä¼šæ‰§è¡Œã€‚è¿™æ˜¾è‘—é™ä½äº†é¡µé¢çš„åˆå§‹åŠ è½½æ—¶é—´ã€‚
        - **ğŸ“Š è¡¨æ ¼æ§ä»¶**: å¯¹äºå¯èƒ½äº§ç”Ÿå¤§é‡æ•°æ®çš„å›¾è¡¨ï¼ˆå¦‚ Apriori ç»“æœã€ä½œè€…æ’è¡Œï¼‰ï¼Œå¢åŠ äº†æ»‘å—ï¼ˆSliderï¼‰æ¥æ§åˆ¶æ˜¾ç¤ºæ¡ç›®æ•°ï¼Œé¿å…äº†æ¸²æŸ“å¤§æ•°æ®è¡¨æ ¼æ—¶çš„æ€§èƒ½ç“¶é¢ˆã€‚
        - **ğŸ§  çŠ¶æ€ç®¡ç†**: é€šè¿‡ `st.session_state` æ™ºèƒ½ç®¡ç†UIçŠ¶æ€ï¼Œç¡®ä¿æ‡’åŠ è½½çš„å†…å®¹åœ¨é¡µé¢åˆ·æ–°åä¾ç„¶å­˜åœ¨ï¼Œæå‡äº†äº¤äº’çš„è¿è´¯æ€§ã€‚

        è¿™äº›ä¼˜åŒ–æ—¨åœ¨ä¸å¼•å…¥å¤æ‚ä¾èµ–çš„å‰æä¸‹ï¼Œä¸ºä¸ªäººç ”ç©¶é¡¹ç›®æä¾›ä¸€ä¸ªæ›´æµç•…ã€æ›´é«˜æ•ˆçš„æ•°æ®å¯è§†åŒ–ä½“éªŒã€‚
        """)
        st.subheader("ç¼“å­˜ç®¡ç†")
        st.info("ç‚¹å‡»å·¦ä¾§ä¾§è¾¹æ çš„ **[æ¸…é™¤æ‰€æœ‰ç¼“å­˜å¹¶åˆ·æ–°]** æŒ‰é’®ï¼Œå¯ä»¥å¼ºåˆ¶æ¸…é™¤æ‰€æœ‰å±‚çº§çš„ç¼“å­˜å’Œä¼šè¯çŠ¶æ€ï¼Œè¿›è¡Œå®Œå…¨é‡ç½®ã€‚")
