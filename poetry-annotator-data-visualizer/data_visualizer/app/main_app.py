import streamlit as st
import plotly.express as px
import pandas as pd
from datetime import datetime, timedelta

from data_visualizer.config import APP_TITLE, DB_PATHS
from data_visualizer.utils import logger
from data_visualizer.app.cache_manager import get_db_manager, get_data_processor
from data_visualizer.app.data_fetcher import (
    get_model_performance_data,
    get_poem_count_by_author_data,
    get_emotion_distribution_data,
    get_frequent_emotion_combinations_data,
    get_frequent_poem_emotion_sets_data_actual,
    get_frequent_poem_emotion_sets_data_frequency,
    get_apriori_results_data,
    get_model_annotation_trends_data,
    get_poem_length_distribution_data
)
from data_visualizer.app.ui_components import (
    display_model_performance,
    display_author_poem_count,
    display_emotion_sunburst,
    display_frequent_combinations
)
from data_visualizer.app.comparison_charts import (
    display_poem_length_comparison_chart,
    display_annotation_trend_comparison_chart
)
from data_visualizer.app.state import AprioriMinerState

def run_app():
    """Main function to run the Streamlit application."""
    st.set_page_config(layout="wide", page_title=APP_TITLE)
    st.title(APP_TITLE)

    # --- Sidebar Controls ---
    with st.sidebar:
        st.title("æ§åˆ¶é¢æ¿")

        if st.button("æ¸…é™¤æ‰€æœ‰ç¼“å­˜å¹¶åˆ·æ–°", help="å¼ºåˆ¶æ¸…é™¤æ‰€æœ‰åº”ç”¨çš„ç¼“å­˜ï¼Œä»æ•°æ®åº“é‡æ–°åŠ è½½æ‰€æœ‰æ•°æ®ã€‚"):
            st.cache_data.clear()
            st.cache_resource.clear()
            st.session_state.clear() # æ¸…é™¤ä¼šè¯çŠ¶æ€
            logger.info("æ‰€æœ‰ç¼“å­˜å·²æ¸…é™¤ï¼Œåº”ç”¨å³å°†åˆ·æ–°ã€‚")
            st.rerun()
        
        # [æ–°å¢] æ¸…é™¤ç£ç›˜ç¼“å­˜æŒ‰é’®
        from data_visualizer.app.disk_cache_manager import get_disk_cache_manager
        if st.button("ğŸ—‘ï¸ æ¸…é™¤ç£ç›˜ç¼“å­˜", help="æ¸…é™¤æŒä¹…åŒ–çš„ç£ç›˜ç¼“å­˜æ–‡ä»¶ï¼Œä¸‹æ¬¡åŠ è½½æ•°æ®æ—¶å°†é‡æ–°è®¡ç®—å¹¶ç¼“å­˜ã€‚"):
            disk_cache_manager = get_disk_cache_manager()
            disk_cache_manager.clear()
            st.success("ç£ç›˜ç¼“å­˜å·²æ¸…é™¤ï¼")
            logger.info("ç”¨æˆ·æ‰‹åŠ¨æ¸…é™¤äº†ç£ç›˜ç¼“å­˜ã€‚")

        st.markdown("---")
        
        view_mode = st.radio("è§†å›¾æ¨¡å¼:", ("å•åº“åˆ†æ", "åŒåº“å¯¹æ¯”"), key="view_mode_selector", horizontal=True)

        db_keys_options = list(DB_PATHS.keys())
        selected_db_key = None
        if view_mode == "å•åº“åˆ†æ":
            selected_db_key = st.selectbox("é€‰æ‹©æ•°æ®åº“:", db_keys_options)
        
        st.markdown("---")
        st.header("æ•°æ®è¿‡æ»¤")
        today = datetime.now()
        default_start_date = today - timedelta(days=90)
        date_range = st.date_input("é€‰æ‹©æ ‡æ³¨æ—¥æœŸèŒƒå›´", value=(default_start_date, today), key="annotation_date_filter")
        if len(date_range) == 2:
            start_date_iso = date_range[0].isoformat() + "T00:00:00Z"
            end_date_iso = date_range[1].isoformat() + "T23:59:59Z"
        else:
            start_date_iso, end_date_iso = None, None

    # --- Main Panel with Tabs ---
    tab1, tab2, tab3, tab4 = st.tabs(["æ ‡æ³¨åˆ†æ", "è¯—è¯æ•°æ®æ¦‚è§ˆ", "æƒ…æ„Ÿåˆ†æ", "å…³äºä¸æ€§èƒ½"])

    # åˆå§‹åŒ–æˆ–è·å– AprioriMinerState
    if 'apriori_state' not in st.session_state or st.session_state.apriori_state.db_key != selected_db_key:
        st.session_state.apriori_state = AprioriMinerState(selected_db_key)
    
    state = st.session_state.apriori_state

    if view_mode == "å•åº“åˆ†æ":
        if selected_db_key:
            with tab1:
                st.header(f"æ ‡æ³¨ç»“æœåˆ†æ: {selected_db_key}")
                st.subheader("æ¨¡å‹æ€§èƒ½æ€»è§ˆ")
                display_model_performance(selected_db_key)
                
                # [OPTIMIZATION] æ·»åŠ å±€éƒ¨åˆ·æ–°æŒ‰é’®
                header_col, button_col = st.columns([0.85, 0.15])
                with header_col:
                    st.subheader("æ ‡æ³¨è¶‹åŠ¿")
                with button_col:
                    if st.button("ğŸ”„ åˆ·æ–°è¶‹åŠ¿", key=f"refresh_trends_{selected_db_key}", help="ä»…é‡æ–°åŠ è½½è¶‹åŠ¿æ•°æ®"):
                        get_model_annotation_trends_data.clear()

                trends_df = get_model_annotation_trends_data(selected_db_key, start_date_iso, end_date_iso)
                if not trends_df.empty:
                    fig_trend = px.line(trends_df.groupby('annotation_date')['completed'].sum().reset_index(), 
                                        x='annotation_date', y='completed', title="æ¯æ—¥æˆåŠŸæ ‡æ³¨æ•°é‡",
                                        labels={'completed': 'æˆåŠŸæ ‡æ³¨æ•°', 'annotation_date': 'æ—¥æœŸ'})
                    st.plotly_chart(fig_trend, use_container_width=True)
                else:
                    st.info("æ‰€é€‰æ—¥æœŸèŒƒå›´å†…æ— æ ‡æ³¨è¶‹åŠ¿æ•°æ®ã€‚")

            with tab2:
                st.header(f"è¯—è¯æ•°æ®æ¦‚è§ˆ: {selected_db_key}")
                
                # [OPTIMIZATION] æ·»åŠ å±€éƒ¨åˆ·æ–°æŒ‰é’®
                header_col, button_col = st.columns([0.85, 0.15])
                with header_col:
                    st.subheader("è¯—äººä½œå“æ•°é‡åˆ†å¸ƒ")
                with button_col:
                    if st.button("ğŸ”„ åˆ·æ–°å›¾è¡¨", key=f"refresh_poets_{selected_db_key}", help="ä»…é‡æ–°åŠ è½½è¯—äººæ•°æ®"):
                        get_poem_count_by_author_data.clear()
                
                top_n_authors = st.slider("æ˜¾ç¤º Top N åˆ›ä½œè€…", 5, 50, 20, key=f"author_count_{selected_db_key}")
                display_author_poem_count(selected_db_key, top_n=top_n_authors)
                
                st.subheader("è¯—è¯é•¿åº¦åˆ†å¸ƒ")
                method_display = st.radio("é€‰æ‹©ç»Ÿè®¡æ–¹æ³•", ('æŒ‰å­—æ•°', 'æŒ‰è¯æ•°'), key=f'len_method_{selected_db_key}', horizontal=True)
                method = {'æŒ‰å­—æ•°': 'characters', 'æŒ‰è¯æ•°': 'words'}[method_display]
                df = get_poem_length_distribution_data(selected_db_key, method)
                if not df.empty:
                    fig = px.bar(df, x='length_band', y='count', title=f'è¯—è¯é•¿åº¦åˆ†å¸ƒ ({method_display})')
                    st.plotly_chart(fig, use_container_width=True)

            with tab3:
                st.header(f"æƒ…æ„Ÿç±»å‹åˆ†æ: {selected_db_key}")
                emotion_dist_df = get_emotion_distribution_data(selected_db_key)

                if emotion_dist_df.empty:
                    st.warning("æœªæ‰¾åˆ°æƒ…æ„Ÿåˆ†å¸ƒæ•°æ®ã€‚è¯·ç¡®ä¿å·²è¿è¡Œæ•°æ®è¿ç§»è„šæœ¬ï¼Œæˆ–è¯¥åº“ä¸­æœ‰å·²å®Œæˆçš„æ ‡æ³¨ã€‚")
                else:
                    # [OPTIMIZATION] æ·»åŠ å±€éƒ¨åˆ·æ–°æŒ‰é’®
                    header_col, button_col = st.columns([0.85, 0.15])
                    with header_col:
                        st.subheader("æƒ…æ„Ÿç±»å‹å±‚çº§åˆ†å¸ƒ")
                    with button_col:
                        if st.button("ğŸ”„ åˆ·æ–°åˆ†å¸ƒ", key=f"refresh_emotion_dist_{selected_db_key}", help="ä»…é‡æ–°åŠ è½½æƒ…æ„Ÿåˆ†å¸ƒæ•°æ®"):
                            get_emotion_distribution_data.clear()
                    display_emotion_sunburst(selected_db_key)

                    st.subheader("æƒ…æ„Ÿé¢‘æ¬¡ç»Ÿè®¡")
                    # ... (rest of emotion frequency code) ...
                    emotion_freq_df = emotion_dist_df.sort_values('count', ascending=False)
                    top_n = st.slider("æ˜¾ç¤º Top N æƒ…æ„Ÿç±»åˆ«", 10, min(100, len(emotion_freq_df)), 20, key=f"emotion_freq_slider_{selected_db_key}")
                    df_to_plot = emotion_freq_df.head(top_n)
                    fig_height = max(400, len(df_to_plot) * 30 + 100)
                    fig_bar_all = px.bar(df_to_plot, x='count', y='name_zh', orientation='h', title=f'æƒ…æ„Ÿç±»åˆ«é¢‘æ¬¡æ’è¡Œ (Top {top_n})', labels={'name_zh': 'æƒ…æ„Ÿç±»åˆ«', 'count': 'å‡ºç°æ¬¡æ•°'}, text='percentage', height=fig_height).update_yaxes(categoryorder="total ascending")
                    st.plotly_chart(fig_bar_all, use_container_width=True)


                    st.subheader("æƒ…æ„Ÿå…±ç°ä¸å…³è”è§„åˆ™æŒ–æ˜")
                    tab_sql_sentence, tab_sql_poem_actual, tab_sql_poem_frequency, tab_apriori = st.tabs(["**å•å¥å†…å…±ç° (SQL è®¡æ•°)**", "**å…¨è¯—å†…å…±ç°-å®é™… (SQL è®¡æ•°)**", "**å…¨è¯—å†…å…±ç°-é¢‘ç‡ (SQL è®¡æ•°)**", "**é«˜çº§æŒ–æ˜ (Apriori)**"])

                    with tab_sql_sentence:
                        st.markdown("âš¡ï¸ **å¿«é€Ÿæ¦‚è§ˆ**: ä½¿ç”¨ SQL ç›´æ¥ç»Ÿè®¡**ä¸€å¥è¯—ä¸­**å…±åŒå‡ºç°çš„å¤šç§æƒ…æ„Ÿã€‚")
                        top_n_sentence = st.slider("é€‰æ‹©æ˜¾ç¤ºç»„åˆæ•°é‡", 5, 50, 15, key=f"combo_sentence_{selected_db_key}")
                        display_frequent_combinations(selected_db_key, top_n_sentence)

                    with tab_sql_poem_actual:
                        st.markdown("âš¡ï¸ **å®é™…æ™®éæ€§**: ä½¿ç”¨ SQL ç›´æ¥ç»Ÿè®¡**ä¸€é¦–è¯—å†…**ï¼ˆåŸºäºæœ€æ–°å®Œæˆæ ‡æ³¨ï¼‰å…±åŒå‡ºç°çš„ä¸åŒæƒ…æ„Ÿã€‚")
                        top_n_poem = st.slider("é€‰æ‹©æ˜¾ç¤ºç»„åˆæ•°é‡", 5, 50, 15, key=f"combo_poem_actual_{selected_db_key}")
                        sets_df = get_frequent_poem_emotion_sets_data_actual(selected_db_key, top_n_poem)
                        if not sets_df.empty:
                            st.dataframe(sets_df, column_config={"set_readable": st.column_config.TextColumn("æƒ…æ„Ÿé›†åˆ", width="large"), "set_count": st.column_config.NumberColumn("å‡ºç°æ¬¡æ•°", format="%d é¦–"), "poem_example": st.column_config.TextColumn("ç¤ºä¾‹è¯—è¯")}, use_container_width=True, hide_index=True)
                        else:
                            st.info("æš‚æ— å…¨è¯—å†…é«˜é¢‘æƒ…æ„Ÿé›†åˆæ•°æ®ã€‚")

                    with tab_sql_poem_frequency:
                        st.markdown("âš¡ï¸ **æ ‡æ³¨é¢‘ç‡**: ä½¿ç”¨ SQL ç›´æ¥ç»Ÿè®¡**ä¸€é¦–è¯—å†…**ï¼ˆåŸºäºæ‰€æœ‰æ ‡æ³¨ï¼‰å…±åŒå‡ºç°çš„ä¸åŒæƒ…æ„Ÿã€‚")
                        top_n_poem = st.slider("é€‰æ‹©æ˜¾ç¤ºç»„åˆæ•°é‡", 5, 50, 15, key=f"combo_poem_frequency_{selected_db_key}")
                        sets_df = get_frequent_poem_emotion_sets_data_frequency(selected_db_key, top_n_poem)
                        if not sets_df.empty:
                            st.dataframe(sets_df, column_config={"set_readable": st.column_config.TextColumn("æƒ…æ„Ÿé›†åˆ", width="large"), "set_count": st.column_config.NumberColumn("å‡ºç°æ¬¡æ•°", format="%d é¦–"), "poem_example": st.column_config.TextColumn("ç¤ºä¾‹è¯—è¯")}, use_container_width=True, hide_index=True)
                        else:
                            st.info("æš‚æ— å…¨è¯—å†…é«˜é¢‘æƒ…æ„Ÿé›†åˆæ•°æ®ã€‚")

                    with tab_apriori:
                        # [OPTIMIZATION 3.1] Apriori æ‡’åŠ è½½
                        st.markdown("ğŸ”¬ **æ·±åº¦æŒ–æ˜**: ä½¿ç”¨ Apriori ç®—æ³•å‘ç°é¢‘ç¹é¡¹é›†ï¼Œæ¢ç´¢ä¸åŒç¨€æœ‰åº¦çš„æƒ…æ„Ÿç»„åˆã€‚")
                        st.info("æ­¤åŠŸèƒ½è®¡ç®—å¯†é›†ã€‚ä¸ºæå‡ä½“éªŒï¼Œå‚æ•°è°ƒæ•´åç‚¹å‡»æŒ‰é’®æ‰ä¼šå¯åŠ¨æŒ–æ˜ã€‚")
                        
                        # å‚æ•°è®¾ç½®å§‹ç»ˆå¯è§ï¼Œæå‡ç”¨æˆ·ä½“éªŒ
                        st.markdown("---")
                        col1, col2 = st.columns(2)
                        with col1:
                            level_map = {"å¥å­çº§åˆ«": "sentence", "è¯—è¯çº§åˆ«": "poem"}
                            selected_level_display = st.radio("åˆ†æç²’åº¦", level_map.keys(), key=f"apriori_level_{selected_db_key}", horizontal=True)
                            level = level_map[selected_level_display]
                        with col2:
                            min_length = st.slider("ç»„åˆä¸­æœ€å°‘æƒ…æ„Ÿæ•°", 2, 5, state.min_length, key=f"apriori_len_{selected_db_key}")
                       
                        min_support_percent = st.slider("æœ€å°æ”¯æŒåº¦ (%)", 0.1, 10.0, state.min_support_percent, step=0.1, key=f"apriori_support_{selected_db_key}", help="ä¸€ä¸ªæƒ…æ„Ÿç»„åˆå‡ºç°çš„é¢‘ç‡ã€‚å€¼è¶Šä½ï¼Œå‘ç°çš„ç»„åˆè¶Šç¨€æœ‰ã€è¶Šå¤šã€‚")
                        
                        # [OPTIMIZATION 3.4] æ€§èƒ½æ§åˆ¶é€‰é¡¹
                        st.markdown("### âš™ï¸ æ€§èƒ½æ§åˆ¶é€‰é¡¹")
                        enable_max_transactions = st.checkbox(
                            "é™åˆ¶æœ€å¤§äº‹åŠ¡æ•°",
                            value=state.enable_max_transactions,
                            key=f"enable_max_transactions_{selected_db_key}",
                            help="å–æ¶ˆå‹¾é€‰ä»¥å¤„ç†æ‰€æœ‰äº‹åŠ¡ï¼ˆå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼‰"
                        )
                        
                        if enable_max_transactions:
                            max_transactions = st.slider(
                                "æœ€å¤§äº‹åŠ¡æ•° (æ§åˆ¶è®¡ç®—è§„æ¨¡)",
                                100, 50000, state.max_transactions,
                                key=f"apriori_max_transactions_{selected_db_key}",
                                help="å‡å°‘æ­¤å€¼å¯åŠ å¿«è®¡ç®—é€Ÿåº¦ä½†å¯èƒ½ä¸¢å¤±ç½•è§æ¨¡å¼"
                            )
                        else:
                            max_transactions = None
                            st.info("å½“å‰è®¾ç½®å°†å¤„ç†æ‰€æœ‰äº‹åŠ¡ï¼Œå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ã€‚")
                        
                        # æ›´æ–°çŠ¶æ€å¯¹è±¡
                        if st.button("ğŸ”„ æ›´æ–°å‚æ•°", key=f"update_params_{selected_db_key}"):
                            state.set_single_parameters(level, min_length, min_support_percent, enable_max_transactions, max_transactions)
                            st.success("å‚æ•°å·²æ›´æ–°ï¼")
                        
                        # æŒ–æ˜æ§åˆ¶æŒ‰é’®
                        button_col1, button_col2, button_col3 = st.columns(3)
                        with button_col1:
                            if st.button("ğŸš€ å¼€å§‹/é‡æ–° Apriori æŒ–æ˜", key=f"start_apriori_{selected_db_key}"):
                                state.start_single_mining()
                                st.rerun()
                        with button_col2:
                            if state.is_mining_single and st.button("â¹ï¸ åœæ­¢æŒ–æ˜", key=f"stop_apriori_{selected_db_key}"):
                                state.reset_single()
                                st.rerun()
                        with button_col3:
                            if not state.is_mining_single and (not state.single_results_df.empty or state.error_message) and st.button("ğŸ—‘ï¸ æ¸…é™¤ç»“æœ", key=f"clear_apriori_{selected_db_key}"):
                                state.reset_single()
                                st.rerun()
                        
                        # æ‰§è¡ŒæŒ–æ˜å¹¶æ˜¾ç¤ºç»“æœ
                        if state.is_mining_single:
                            with st.spinner("æ­£åœ¨è¿›è¡Œ Apriori æŒ–æ˜ï¼Œè¯·ç¨å€™..."):
                                try:
                                    apriori_results_df = get_apriori_results_data(selected_db_key, state.level, state.get_min_support(), state.min_length, state.max_transactions)
                                    state.set_single_results(apriori_results_df)
                                except Exception as e:
                                    state.set_single_error(f"æŒ–æ˜è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                                    logger.error(f"Apriori æŒ–æ˜é”™è¯¯: {e}", exc_info=True)
                            
                        # æ˜¾ç¤ºç»“æœæˆ–é”™è¯¯
                        if not state.single_results_df.empty:
                            st.markdown("---")
                            st.subheader(f"æŒ–æ˜ç»“æœ (æ”¯æŒåº¦ > {state.min_support_percent:.1f}%)")
                            result_count = len(state.single_results_df)
                            if result_count > 1:
                                top_n_apriori = st.slider("æ˜¾ç¤ºå‰ N æ¡ç»“æœ", 1, result_count, min(25, result_count), key=f"apriori_rows_{selected_db_key}")
                                display_df = state.single_results_df.head(top_n_apriori)
                            else:
                                st.info(f"å‘ç° {result_count} ä¸ªç»“æœ")
                                display_df = state.single_results_df
                            
                            st.dataframe(
                                display_df, 
                                column_config={
                                    "itemsets_readable": st.column_config.TextColumn("é«˜é¢‘æƒ…æ„Ÿç»„åˆ", width="large"), 
                                    "support": st.column_config.NumberColumn("æ”¯æŒåº¦", format="%.4f"), 
                                    "length": st.column_config.NumberColumn("ç»„åˆé•¿åº¦")
                                }, 
                                use_container_width=True, 
                                hide_index=True
                            )
                        elif state.error_message:
                            st.error(state.error_message)
                        elif state.is_mining_single:
                            # This case should be rare as mining is synchronous, but good for consistency
                            st.info("æŒ–æ˜å·²å¯åŠ¨ï¼Œè¯·ç­‰å¾…...")
                        else:
                            st.info("ç‚¹å‡» 'å¼€å§‹/é‡æ–° Apriori æŒ–æ˜' æŒ‰é’®ä»¥å¯åŠ¨æŒ–æ˜ã€‚")
    else:
        # --- Comparison View Mode ---
        db_keys_to_compare = db_keys_options[:2] # Default to first two
        
        # åˆå§‹åŒ–æˆ–è·å–å¯¹æ¯”æ¨¡å¼çš„ AprioriMinerState
        if 'apriori_state_compare' not in st.session_state:
            st.session_state.apriori_state_compare = AprioriMinerState("compare_session")
        
        state_compare = st.session_state.apriori_state_compare

        with tab1:
            st.header("æ ‡æ³¨ç»“æœåˆ†æ (å¯¹æ¯”)")
            st.subheader("æ¨¡å‹æ€§èƒ½æ€»è§ˆ")
            col1, col2 = st.columns(2)
            with col1:
                st.subheader(db_keys_to_compare[0])
                display_model_performance(db_keys_to_compare[0])
            with col2:
                st.subheader(db_keys_to_compare[1])
                display_model_performance(db_keys_to_compare[1])
            st.subheader("æ ‡æ³¨è¶‹åŠ¿ (å åŠ å¯¹æ¯”)")
            display_annotation_trend_comparison_chart(db_keys_to_compare, start_date_iso, end_date_iso)


        with tab2:
            st.header("è¯—è¯æ•°æ®æ¦‚è§ˆ (å¯¹æ¯”)")
            st.subheader("åˆ›ä½œè€…ä½œå“æ•°é‡ (å¹¶æ’å¯¹æ¯”)")
            col1, col2 = st.columns(2)
            with col1:
                display_author_poem_count(db_keys_to_compare[0])
            with col2:
                display_author_poem_count(db_keys_to_compare[1])
            st.subheader("è¯—è¯é•¿åº¦åˆ†å¸ƒ (å åŠ å¯¹æ¯”)")
            method_display = st.radio("é€‰æ‹©ç»Ÿè®¡æ–¹æ³•", ('æŒ‰å­—æ•°', 'æŒ‰è¯æ•°'), key='len_method_compare', horizontal=True)
            method = {'æŒ‰å­—æ•°': 'characters', 'æŒ‰è¯æ•°': 'words'}[method_display]
            display_poem_length_comparison_chart(db_keys_to_compare, method, method_display)


        with tab3:
            st.header("æƒ…æ„Ÿåˆ†æ (å¯¹æ¯”)")
            st.subheader("æƒ…æ„Ÿå±‚çº§åˆ†å¸ƒ (å¹¶æ’å¯¹æ¯”)")
            col1, col2 = st.columns(2)
            with col1:
                st.subheader(db_keys_to_compare[0])
                display_emotion_sunburst(db_keys_to_compare[0])
            with col2:
                st.subheader(db_keys_to_compare[1])
                display_emotion_sunburst(db_keys_to_compare[1])
            st.markdown("---")
            st.subheader(f"èšåˆå¯¹æ¯”ï¼šæƒ…æ„Ÿåˆ†ç±»å¼•ç”¨ç™¾åˆ†æ¯”å·®å¼‚ ({db_keys_to_compare[1]} vs {db_keys_to_compare[0]})")
            sunburst_df1 = get_emotion_distribution_data(db_keys_to_compare[0])
            sunburst_df2 = get_emotion_distribution_data(db_keys_to_compare[1])
            if not sunburst_df1.empty and not sunburst_df2.empty:
                df1_comp = sunburst_df1[['name_zh', 'percentage', 'count']].rename(columns={'percentage': f'percentage_{db_keys_to_compare[0]}','count': f'count_{db_keys_to_compare[0]}'})
                df2_comp = sunburst_df2[['name_zh', 'percentage', 'count']].rename(columns={'percentage': f'percentage_{db_keys_to_compare[1]}','count': f'count_{db_keys_to_compare[1]}'})
                merged_comp_df = pd.merge(df1_comp, df2_comp, on='name_zh', how='outer').fillna(0)
                merged_comp_df['percentage_diff'] = merged_comp_df[f'percentage_{db_keys_to_compare[1]}'] - merged_comp_df[f'percentage_{db_keys_to_compare[0]}']
                merged_comp_df = merged_comp_df.sort_values(by='percentage_diff', ascending=False, key=abs)
                st.dataframe(merged_comp_df, column_config={'name_zh': "æƒ…æ„Ÿåˆ†ç±»", f'percentage_{db_keys_to_compare[0]}': st.column_config.NumberColumn(f"{db_keys_to_compare[0]} å æ¯” (%)", format="%.2f"), f'percentage_{db_keys_to_compare[1]}': st.column_config.NumberColumn(f"{db_keys_to_compare[1]} å æ¯” (%)", format="%.2f"), 'percentage_diff': st.column_config.NumberColumn(f"å¢å‡ç™¾åˆ†ç‚¹ ({db_keys_to_compare[1]}-{db_keys_to_compare[0]})", format="%+.2f"), f'count_{db_keys_to_compare[0]}': st.column_config.NumberColumn(f"{db_keys_to_compare[0]} å¼•ç”¨æ•°"), f'count_{db_keys_to_compare[1]}': st.column_config.NumberColumn(f"{db_keys_to_compare[1]} å¼•ç”¨æ•°")}, column_order=['name_zh', f'percentage_{db_keys_to_compare[0]}', f'percentage_{db_keys_to_compare[1]}', 'percentage_diff', f'count_{db_keys_to_compare[0]}', f'count_{db_keys_to_compare[1]}'], use_container_width=True, hide_index=True)
            else:
                st.info("ä¸€ä¸ªæˆ–ä¸¤ä¸ªæ•°æ®åº“ç¼ºå°‘æƒ…æ„Ÿåˆ†å¸ƒæ•°æ®ï¼Œæ— æ³•è¿›è¡Œèšåˆå¯¹æ¯”ã€‚")

            st.markdown("---")
            
            st.subheader(f"èšåˆå¯¹æ¯”ï¼šé«˜é¢‘æƒ…æ„Ÿç»„åˆæ”¯æŒåº¦å·®å¼‚ ({db_keys_to_compare[1]} vs {db_keys_to_compare[0]})")
            st.info("ä½¿ç”¨ Apriori ç®—æ³•åœ¨ **è¯—è¯çº§åˆ«** è¿›è¡Œå¯¹æ¯”æŒ–æ˜ã€‚å‚æ•°è°ƒæ•´åç‚¹å‡»æŒ‰é’®æ‰ä¼šå¯åŠ¨æŒ–æ˜ã€‚")
            
            # å‚æ•°è®¾ç½®å§‹ç»ˆå¯è§ï¼Œæå‡ç”¨æˆ·ä½“éªŒ
            col_a, col_b, col_c = st.columns(3)
            with col_a:
                min_length_compare = st.slider("ç»„åˆä¸­æœ€å°‘æƒ…æ„Ÿæ•°", 2, 5, state_compare.compare_min_length, key="apriori_len_compare")
            with col_b:
                min_support_percent_compare = st.slider("æœ€å°æ”¯æŒåº¦ (%)", 0.1, 5.0, state_compare.compare_min_support_percent, step=0.1, key="apriori_support_compare")
            with col_c:
                # [OPTIMIZATION 3.4] æ€§èƒ½æ§åˆ¶
                enable_max_transactions_compare = st.checkbox(
                    "é™åˆ¶æœ€å¤§äº‹åŠ¡æ•°", value=state_compare.compare_enable_max_transactions, key="enable_max_transactions_compare"
                )
                if enable_max_transactions_compare:
                    max_transactions_compare = st.number_input(
                        "æœ€å¤§äº‹åŠ¡æ•°", min_value=100, max_value=50000, value=state_compare.compare_max_transactions, key="apriori_max_transactions_compare"
                    )
                else:
                    max_transactions_compare = None
            
            # æ›´æ–°çŠ¶æ€å¯¹è±¡
            if st.button("ğŸ”„ æ›´æ–°å¯¹æ¯”å‚æ•°", key="update_params_compare"):
                state_compare.set_compare_parameters(min_length_compare, min_support_percent_compare, enable_max_transactions_compare, max_transactions_compare)
                st.success("å¯¹æ¯”å‚æ•°å·²æ›´æ–°ï¼")

            # æŒ–æ˜æ§åˆ¶æŒ‰é’®
            button_col1, button_col2, button_col3 = st.columns(3)
            with button_col1:
                if st.button("ğŸš€ å¼€å§‹/é‡æ–°å¯¹æ¯”æŒ–æ˜", key="start_apriori_compare"):
                    state_compare.start_compare_mining()
                    st.rerun()
            with button_col2:
                if state_compare.is_mining_compare and st.button("â¹ï¸ åœæ­¢å¯¹æ¯”æŒ–æ˜", key="stop_apriori_compare"):
                    state_compare.reset_compare()
                    st.rerun()
            with button_col3:
                if not state_compare.is_mining_compare and (not state_compare.compare_results_df.empty or state_compare.error_message) and st.button("ğŸ—‘ï¸ æ¸…é™¤å¯¹æ¯”ç»“æœ", key="clear_apriori_compare"):
                    state_compare.reset_compare()
                    st.rerun()

            # æ‰§è¡ŒæŒ–æ˜
            if state_compare.is_mining_compare:
                with st.spinner("æ­£åœ¨ä¸ºä¸¤ä¸ªæ•°æ®åº“æ‰§è¡Œ Apriori å¯¹æ¯”æŒ–æ˜..."):
                    try:
                        apriori_df1 = get_apriori_results_data(db_keys_to_compare[0], 'poem', state_compare.get_compare_min_support(), state_compare.compare_min_length, state_compare.compare_max_transactions)
                        apriori_df2 = get_apriori_results_data(db_keys_to_compare[1], 'poem', state_compare.get_compare_min_support(), state_compare.compare_min_length, state_compare.compare_max_transactions)

                        if apriori_df1.empty and apriori_df2.empty:
                             state_compare.set_compare_error(f"åœ¨å½“å‰è®¾ç½®ä¸‹ï¼Œä¸¤ä¸ªæ•°æ®åº“å‡æœªå‘ç°ä»»ä½•æƒ…æ„Ÿç»„åˆã€‚è¯·å°è¯•é™ä½å‚æ•°ã€‚")
                        else:
                            df1_ap_comp = apriori_df1[['itemsets_readable', 'support']].rename(columns={'support': f'support_{db_keys_to_compare[0]}'})
                            df2_ap_comp = apriori_df2[['itemsets_readable', 'support']].rename(columns={'support': f'support_{db_keys_to_compare[1]}'})
                            merged_ap_df = pd.merge(df1_ap_comp, df2_ap_comp, on='itemsets_readable', how='outer').fillna(0)
                            if not merged_ap_df.empty:
                                merged_ap_df['support_diff'] = merged_ap_df[f'support_{db_keys_to_compare[1]}'] - merged_ap_df[f'support_{db_keys_to_compare[0]}']
                                merged_ap_df = merged_ap_df[(merged_ap_df[f'support_{db_keys_to_compare[0]}'] > 0) | (merged_ap_df[f'support_{db_keys_to_compare[1]}'] > 0)]
                                merged_ap_df = merged_ap_df.reindex(merged_ap_df['support_diff'].abs().sort_values(ascending=False).index)
                                state_compare.set_compare_results(merged_ap_df)
                            else:
                                state_compare.set_compare_error("åˆå¹¶åçš„å¯¹æ¯”ç»“æœä¸ºç©ºã€‚")
                    except Exception as e:
                        state_compare.set_compare_error(f"å¯¹æ¯”æŒ–æ˜è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                        logger.error(f"Apriori å¯¹æ¯”æŒ–æ˜é”™è¯¯: {e}", exc_info=True)

            # æ˜¾ç¤ºç»“æœæˆ–é”™è¯¯
            if not state_compare.compare_results_df.empty:
                result_count_comp = len(state_compare.compare_results_df)
                if result_count_comp > 1:
                    top_n_apriori_comp = st.slider("æ˜¾ç¤ºå‰ N æ¡å¯¹æ¯”ç»“æœ", 1, result_count_comp, min(25, result_count_comp), key="apriori_rows_compare")
                    display_df_comp = state_compare.compare_results_df.head(top_n_apriori_comp)
                else:
                    display_df_comp = state_compare.compare_results_df

                st.dataframe(display_df_comp, column_config={'itemsets_readable': "é«˜é¢‘æƒ…æ„Ÿç»„åˆ", f'support_{db_keys_to_compare[0]}': st.column_config.NumberColumn(f"{db_keys_to_compare[0]} æ”¯æŒåº¦", format="%.4f"), f'support_{db_keys_to_compare[1]}': st.column_config.NumberColumn(f"{db_keys_to_compare[1]} æ”¯æŒåº¦", format="%.4f"), 'support_diff': st.column_config.NumberColumn(f"æ”¯æŒåº¦å·®å¼‚ ({db_keys_to_compare[1]}-{db_keys_to_compare[0]})", format="%+.4f")}, column_order=['itemsets_readable', f'support_{db_keys_to_compare[0]}', f'support_{db_keys_to_compare[1]}', 'support_diff'], use_container_width=True, hide_index=True)
            
            elif state_compare.error_message:
                st.error(state_compare.error_message)
            elif state_compare.is_mining_compare:
                 # This case should be rare as mining is synchronous, but good for consistency
                st.info("å¯¹æ¯”æŒ–æ˜å·²å¯åŠ¨ï¼Œè¯·ç­‰å¾…...")
            else:
                st.info("ç‚¹å‡» 'å¼€å§‹/é‡æ–°å¯¹æ¯”æŒ–æ˜' æŒ‰é’®ä»¥å¯åŠ¨æŒ–æ˜ã€‚")

    with tab4:
        st.header("å…³äºä¸æ€§èƒ½")
        st.markdown("""
        ### åº”ç”¨ä¼˜åŒ–è¯´æ˜
        æ­¤ç‰ˆæœ¬æ ¹æ®è½»é‡çº§æ€§èƒ½ä¼˜åŒ–æ–¹æ¡ˆè¿›è¡Œäº†å‡çº§ï¼Œä¸»è¦æ”¹è¿›åŒ…æ‹¬ï¼š

        - **ğŸ¯ å±€éƒ¨åˆ·æ–°**: å¤šæ•°å›¾è¡¨å·²é…å¤‡ç‹¬ç«‹çš„åˆ·æ–°æŒ‰é’® (ğŸ”„)ï¼Œåªä¼šæ›´æ–°å¯¹åº”å›¾è¡¨çš„æ•°æ®ï¼Œè€Œéæ•´ä¸ªé¡µé¢ï¼Œå“åº”æ›´å¿«æ·ã€‚
        - **âš¡ï¸ æ‡’åŠ è½½**: è®¡ç®—å¯†é›†çš„ Apriori æŒ–æ˜åŠŸèƒ½ç°å·²é»˜è®¤å…³é—­ï¼Œéœ€ç‚¹å‡»â€œå¼€å§‹æŒ–æ˜â€æŒ‰é’®åæ‰ä¼šæ‰§è¡Œã€‚è¿™æ˜¾è‘—é™ä½äº†é¡µé¢çš„åˆå§‹åŠ è½½æ—¶é—´ã€‚
        - **ğŸ“Š è¡¨æ ¼æ§ä»¶**: å¯¹äºå¯èƒ½äº§ç”Ÿå¤§é‡æ•°æ®çš„å›¾è¡¨ï¼ˆå¦‚ Apriori ç»“æœã€ä½œè€…æ’è¡Œï¼‰ï¼Œå¢åŠ äº†æ»‘å—ï¼ˆSliderï¼‰æ¥æ§åˆ¶æ˜¾ç¤ºæ¡ç›®æ•°ï¼Œé¿å…äº†æ¸²æŸ“å¤§æ•°æ®è¡¨æ ¼æ—¶çš„æ€§èƒ½ç“¶é¢ˆã€‚
        - **ğŸ§  çŠ¶æ€ç®¡ç†**: é€šè¿‡ `st.session_state` æ™ºèƒ½ç®¡ç†UIçŠ¶æ€ï¼Œç¡®ä¿æ‡’åŠ è½½çš„å†…å®¹åœ¨é¡µé¢åˆ·æ–°åä¾ç„¶å­˜åœ¨ï¼Œæå‡äº†äº¤äº’çš„è¿è´¯æ€§ã€‚

        è¿™äº›ä¼˜åŒ–æ—¨åœ¨ä¸å¼•å…¥å¤æ‚ä¾èµ–çš„å‰æä¸‹ï¼Œä¸ºä¸ªäººç ”ç©¶é¡¹ç›®æä¾›ä¸€ä¸ªæ›´æµç•…ã€æ›´é«˜æ•ˆçš„æ•°æ®å¯è§†åŒ–ä½“éªŒã€‚
        """)
        st.subheader("ç¼“å­˜ç®¡ç†")
        st.info("ç‚¹å‡»å·¦ä¾§ä¾§è¾¹æ çš„ **[æ¸…é™¤æ‰€æœ‰ç¼“å­˜å¹¶åˆ·æ–°]** æŒ‰é’®ï¼Œå¯ä»¥å¼ºåˆ¶æ¸…é™¤æ‰€æœ‰å±‚çº§çš„ç¼“å­˜å’Œä¼šè¯çŠ¶æ€ï¼Œè¿›è¡Œå®Œå…¨é‡ç½®ã€‚")
